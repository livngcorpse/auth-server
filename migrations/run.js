require('dotenv').config();
const fs = require('fs');
const path = require('path');
const { Pool } = require('pg');

const pool = new Pool({
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT) || 5432,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  ssl: process.env.DB_SSL === 'true' ? {
    rejectUnauthorized: false
  } : false
});

const runMigrations = async () => {
  try {
    console.log('üîÑ Connecting to database...');
    await pool.query('SELECT NOW()');
    console.log('‚úÖ Database connected');
    
    // Read migration file
    const migrationPath = path.join(__dirname, '001_initial_schema.sql');
    const migrationSQL = fs.readFileSync(migrationPath, 'utf8');
    
    console.log('üîÑ Running migration: 001_initial_schema.sql');
    
    // Execute migration
    await pool.query(migrationSQL);
    
    console.log('‚úÖ Migration completed successfully');
    
    // Verify tables
    const result = await pool.query(`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public' 
      ORDER BY table_name
    `);
    
    console.log('\nüìä Created tables:');
    result.rows.forEach(row => {
      console.log(`  - ${row.table_name}`);
    });
    
    await pool.end();
    process.exit(0);
  } catch (error) {
    console.error('‚ùå Migration failed:', error.message);
    console.error(error.stack);
    await pool.end();
    process.exit(1);
  }
};

runMigrations();